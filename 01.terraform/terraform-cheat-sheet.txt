Prerequisites (One-time)
Install tools

terraform --version
gcloud --version

Authenticate with GCP
gcloud auth application-default login


üìå Terraform will automatically pick up ADC (Application Default Credentials).

Basic Terraform Project Structure
terraform-gcp/
‚îú‚îÄ‚îÄ main.tf
‚îú‚îÄ‚îÄ variables.tf
‚îú‚îÄ‚îÄ outputs.tf
‚îú‚îÄ‚îÄ provider.tf
‚îú‚îÄ‚îÄ terraform.tfvars


GCP Provider Configuration
provider.tf
terraform {
  required_version = ">= 1.5.0"

  required_providers {
    google = {
      source  = "hashicorp/google"
      version = "~> 5.0"
    }
  }
}

provider "google" {
  project = var.project_id
  region  = var.region
  zone    = var.zone
}


Variables & tfvars
variables.tf
variable "project_id" {
  type = string
}

variable "region" {
  type    = string
  default = "us-central1"
}

variable "zone" {
  type    = string
  default = "us-central1-a"
}

terraform.tfvars
project_id = "my-gcp-project"
region     = "us-central1"
zone       = "us-central1-a"


Core Terraform Commands (Must Know)
terraform init
terraform validate
terraform plan
terraform apply
terraform destroy

Auto approve
terraform apply -auto-approve
terraform destroy -auto-approve

GCS Bucket (Very Common for DE)
resource "google_storage_bucket" "raw_data" {
  name          = "${var.project_id}-raw-data"
  location      = var.region
  storage_class = "STANDARD"

  versioning {
    enabled = true
  }
}


üìå Used for:

Raw data lake

Spark input/output

BigQuery external tables

BigQuery Dataset & Table
Dataset
resource "google_bigquery_dataset" "analytics" {
  dataset_id = "analytics"
  location   = var.region
}

Table
resource "google_bigquery_table" "events" {
  dataset_id = google_bigquery_dataset.analytics.dataset_id
  table_id   = "events"

  schema = file("schema.json")
}

BigQuery Dataset & Table
Dataset
resource "google_bigquery_dataset" "analytics" {
  dataset_id = "analytics"
  location   = var.region
}

Table
resource "google_bigquery_table" "events" {
  dataset_id = google_bigquery_dataset.analytics.dataset_id
  table_id   = "events"

  schema = file("schema.json")
}

Service Account + IAM (Critical)
Service Account
resource "google_service_account" "de_sa" {
  account_id   = "de-service-account"
  display_name = "Data Engineer SA"
}

IAM Binding
resource "google_project_iam_member" "bq_admin" {
  project = var.project_id
  role    = "roles/bigquery.admin"
  member  = "serviceAccount:${google_service_account.de_sa.email}"
}


üìå IAM is one of the most asked GCP Terraform topics.

VPC & Subnet (Networking Basics)
resource "google_compute_network" "vpc" {
  name                    = "de-vpc"
  auto_create_subnetworks = false
}

resource "google_compute_subnetwork" "subnet" {
  name          = "de-subnet"
  region        = var.region
  network       = google_compute_network.vpc.id
  ip_cidr_range = "10.0.0.0/24"
}


Outputs
output "bucket_name" {
  value = google_storage_bucket.raw_data.name
}

output "vm_ip" {
  value = google_compute_instance.vm.network_interface[0].access_config[0].nat_ip
}

State Management (Important Concept)
Local state (default)
terraform.tfstate

Remote state in GCS (recommended)
terraform {
  backend "gcs" {
    bucket  = "terraform-state-bucket"
    prefix  = "gcp/de"
  }
}


üìå This is production-grade practice.

Import Existing GCP Resources
terraform import google_storage_bucket.raw_data my-existing-bucket


Used when:

Infra already exists

Migrating to Terraform

Destroy Specific Resource
terraform destroy -target=google_compute_instance.vm


‚ö†Ô∏è Use carefully.
Common Errors & Fixes
‚ùå Permission denied

‚û°Ô∏è Missing IAM role
Fix:

gcloud projects add-iam-policy-binding ...

‚ùå API not enabled

Fix:

gcloud services enable compute.googleapis.com